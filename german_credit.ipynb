{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed1d5e-0efe-480b-b85b-c05c440cae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#FIX: Set Pandas option to explicitly adopt future downcasting behavior,\n",
    "# which eliminates the FutureWarning about 'df['class'] = df['class'].replace(class_mapping).astype(int)'\n",
    "pd.set_option('future.no_silent_downcasting', True) \n",
    "\n",
    "# Set a style for visualizations\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "## ðŸ’» Problem 2: German Credit Dataset (70 points)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('GermanCredit.csv')\n",
    "\n",
    "# --- Robust Column Name Cleaning ---\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('-', '_').str.replace(\"'\", \"\")\n",
    "\n",
    "print(f\"Initial DataFrame Shape: {df.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# âš ï¸ CRITICAL DEBUGGING STEP: Output current column names\n",
    "print(\"Current DataFrame Columns (after initial cleaning):\")\n",
    "print(list(df.columns))\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ---\n",
    "## Preprocessing (29 pts)\n",
    "\n",
    "### [8 pts] Drop the 3 columns that contribute the least to the dataset. These would be the columns with the highest number of non-zero 'none' values. Break ties by going left to right in columns.\n",
    "\n",
    "def drop_n_least_contributing_columns(data, n=3):\n",
    "    \"\"\"Drops the n columns with the highest count of non-zero 'none' values.\"\"\"\n",
    "    none_counts = {}\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            count = (data[col].astype(str).str.lower() == 'none').sum()\n",
    "            if count > 0:\n",
    "                none_counts[col] = count\n",
    "\n",
    "    none_series = pd.Series(none_counts).sort_values(ascending=False)\n",
    "    columns_to_drop = none_series.index[:n].tolist()\n",
    "\n",
    "    df_dropped = data.drop(columns=columns_to_drop, inplace=False)\n",
    "    \n",
    "    print(f\"Columns dropped: {columns_to_drop}\")\n",
    "    print(f\"New DataFrame Shape: {df_dropped.shape}\")\n",
    "    \n",
    "    return df_dropped\n",
    "\n",
    "df = drop_n_least_contributing_columns(df, n=3)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [4 pts] Certain values in some of the columns contain unnecessary apostrophes (â€˜). Remove the apostrophes.\n",
    "\n",
    "string_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "df[string_cols] = df[string_cols].apply(\n",
    "    lambda col: col.str.replace(\"'\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "print(\"Apostrophes removed from values in all string columns.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [5 pts] The checking_status column has values in 4 categories: 'no checking', '<0', '0<=X<200', and '>=200'. Change these to 'No Checking', 'Low', 'Medium', and 'High' respectively.\n",
    "\n",
    "checking_status_mapping = {\n",
    "    'no checking': 'No Checking',\n",
    "    '<0': 'Low',\n",
    "    '0<=x<200': 'Medium',\n",
    "    '>=200': 'High'\n",
    "}\n",
    "\n",
    "df['checking_status'] = df['checking_status'].map(checking_status_mapping)\n",
    "print(\"Checking status categories updated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [5 pts] The savings_status column has values in 4 categories: 'no known savings', '<100', '100<=X<500', '500<=X<1000', and '>=1000'. Change these to 'No Savings', 'Low', 'Medium', 'High', and 'High' respectively.\n",
    "\n",
    "savings_status_mapping = {\n",
    "    'no known savings': 'No Savings',\n",
    "    '<100': 'Low',\n",
    "    '100<=x<500': 'Medium',\n",
    "    '500<=x<1000': 'High',\n",
    "    '>=1000': 'High'\n",
    "}\n",
    "\n",
    "df['savings_status'] = df['savings_status'].map(savings_status_mapping)\n",
    "print(\"Savings status categories updated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [3 pts] Change class column values from 'good' to '1' and 'bad' to '0'.\n",
    "\n",
    "class_mapping = {\n",
    "    'good': 1,\n",
    "    'bad': 0\n",
    "}\n",
    "\n",
    "df['class'] = df['class'].replace(class_mapping).astype(int)\n",
    "print(\"Class column values updated to 1 (good) and 0 (bad).\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [4 pts] Change the employment column value 'unemployed' to 'Unemployed', and for the others, change to 'Amateur', 'Professional', 'Experienced' and 'Expert', depending on year range.\n",
    "\n",
    "employment_mapping = {\n",
    "    'unemployed': 'Unemployed',\n",
    "    '<1': 'Amateur',\n",
    "    '1<=x<4': 'Professional',\n",
    "    '4<=x<7': 'Experienced',\n",
    "    '>=7': 'Expert'\n",
    "}\n",
    "\n",
    "df['employment'] = df['employment'].replace(employment_mapping)\n",
    "print(\"Employment categories updated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ---\n",
    "## Analysis (17 pts)\n",
    "\n",
    "### [5 pts] Often we need to find correlations between categorical attributes... Do this for the following two counts.\n",
    "\n",
    "#### [3 pts] Get the count of each category of foreign workers (yes and no) for each class of credit (good and bad).\n",
    "\n",
    "cross_tab_foreign_worker_class = pd.crosstab(\n",
    "    df['foreign_worker'], \n",
    "    df['class'], \n",
    "    margins=True, \n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "print(\"Count of foreign_worker categories for each class (1=Good, 0=Bad):\")\n",
    "print(cross_tab_foreign_worker_class)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "#### [2 pts] Similarly, get the count of each category of employment for each category of saving_status.\n",
    "\n",
    "cross_tab_employment_savings = pd.crosstab(\n",
    "    df['employment'], \n",
    "    df['savings_status'], \n",
    "    margins=True, \n",
    "    margins_name='Total'\n",
    ")\n",
    "\n",
    "print(\"Count of employment categories for each saving_status category:\")\n",
    "print(cross_tab_employment_savings)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [4 pts] Find the average credit_amount of single males that have 4<=X<7 years of employment. You can leave the raw result as is, no need for rounding.\n",
    "\n",
    "filtered_df = df[\n",
    "    (df['personal_status'] == 'male single') & \n",
    "    (df['employment'] == 'Experienced')\n",
    "]\n",
    "\n",
    "average_credit_amount = filtered_df['credit_amount'].mean()\n",
    "\n",
    "print(f\"Average credit_amount for single males with 'Experienced' employment: \\n{average_credit_amount}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [4 pts] Find the average credit duration for each of the job types. You can leave the raw result as is, no need for rounding.\n",
    "\n",
    "# FINAL FIX: Uses 'duration' as the column name, with an attempt at 'duration_in_month' as fallback.\n",
    "try:\n",
    "    average_duration_by_job = df.groupby('job')['duration'].mean()\n",
    "except KeyError:\n",
    "    try:\n",
    "        average_duration_by_job = df.groupby('job')['duration_in_month'].mean()\n",
    "    except KeyError:\n",
    "        print(\"ERROR: Neither 'duration' nor 'duration_in_month' found. Please check your columns.\")\n",
    "        average_duration_by_job = pd.Series([\"Column not found\"], index=[\"Error\"])\n",
    "\n",
    "print(\"Average credit duration (in months) for each job type:\")\n",
    "print(average_duration_by_job)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "### [4 pts] For the purpose 'education', what is the most common checking_status and savings_status?\n",
    "\n",
    "education_df = df[df['purpose'] == 'education']\n",
    "\n",
    "most_common_checking = education_df['checking_status'].mode()[0]\n",
    "most_common_savings = education_df['savings_status'].mode()[0]\n",
    "\n",
    "print(f\"For the purpose 'education':\")\n",
    "print(f\"    Most common checking status: {most_common_checking}\")\n",
    "print(f\"    Most common savings status: {most_common_savings}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# ---\n",
    "## Visualization (24 pts)\n",
    "\n",
    "### [9 pts] Plot subplots of two bar charts: one for savings_status (x-axis) to personal status (y-axis), and another for checking_status (x-axis) to personal_status (y-axis). In each of the charts, each personal status category bar (number of people in that category) should be of a different color.\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Chart 1: savings_status vs. personal_status\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x='savings_status',\n",
    "    hue='personal_status',\n",
    "    ax=axes[0],\n",
    "    palette='viridis'\n",
    ")\n",
    "axes[0].set_title('Count of Personal Status by Savings Status')\n",
    "axes[0].set_xlabel('Savings Status')\n",
    "axes[0].set_ylabel('Number of People')\n",
    "axes[0].tick_params(axis='x', rotation=10)\n",
    "axes[0].legend(title='Personal Status', loc='upper right')\n",
    "\n",
    "# Chart 2: checking_status vs. personal_status\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x='checking_status',\n",
    "    hue='personal_status',\n",
    "    ax=axes[1],\n",
    "    palette='plasma'\n",
    ")\n",
    "axes[1].set_title('Count of Personal Status by Checking Status')\n",
    "axes[1].set_xlabel('Checking Status')\n",
    "axes[1].set_ylabel('Number of People')\n",
    "axes[1].tick_params(axis='x', rotation=10)\n",
    "axes[1].legend(title='Personal Status', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "### [9 pts] For people having credit_amount more than 4000, plot a bar graph which maps property_magnitude (x-axis) to the average customer age for that magnitude (y-axis).\n",
    "\n",
    "high_credit_df = df[df['credit_amount'] > 4000].copy()\n",
    "avg_age_by_property = high_credit_df.groupby('property_magnitude')['age'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# â­ BEST FIX: Removed 'palette' argument from barplot without 'hue' to prevent Seaborn warning\n",
    "sns.barplot(\n",
    "    data=avg_age_by_property,\n",
    "    x='property_magnitude',\n",
    "    y='age'\n",
    ")\n",
    "\n",
    "plt.title('Average Customer Age by Property Magnitude (for Credit Amount > 4000)')\n",
    "plt.xlabel('Property Magnitude')\n",
    "plt.ylabel('Average Age')\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### [6 pts] For people with a \"High\" savings_status and age above 40, use subplots to plot the following pie charts: Personal status, Credit history, Job\n",
    "\n",
    "filtered_for_pie = df[\n",
    "    (df['savings_status'] == 'High') & \n",
    "    (df['age'] > 40)\n",
    "].copy()\n",
    "\n",
    "pie_columns = ['personal_status', 'credit_history', 'job']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "for i, col in enumerate(pie_columns):\n",
    "    counts = filtered_for_pie[col].value_counts()\n",
    "    \n",
    "    axes[i].pie(\n",
    "        counts,\n",
    "        labels=counts.index,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 10}\n",
    "    )\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=12)\n",
    "    axes[i].axis('equal')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe185da-f266-466b-9e32-01aeb1b38a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
