{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dataset\n",
    "# df = pd.read_csv(\"dirty_financial_transactions.csv\")\n",
    "\n",
    "# # Take 1000 random rows\n",
    "# sample_df = df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # Save to a new CSV file\n",
    "# sample_df.to_csv(\"dirty_financial_transactions_1k.csv\", index=False)\n",
    "\n",
    "# print(\"âœ… Saved 1000-row sample to dirty_financial_transactions_1k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing Transaction_ID or Customer_ID (will be dropped):\n",
      "    Transaction_ID Transaction_Date Customer_ID    Product_Name  Quantity  \\\n",
      "36             NaN       2025-02-30       C4919      Smartphone     647.0   \n",
      "41          T89578       2023-13-01         NaN      Headphones     750.0   \n",
      "73          T14532       2025-02-30         NaN      Smartphone       7.0   \n",
      "78          T99090       2020-01-28         NaN  Coffee Machine     915.0   \n",
      "90             NaN       2021-07-17        C312               T      -2.0   \n",
      "..             ...              ...         ...             ...       ...   \n",
      "936            NaN       2023-12-11       C3855      Headphones       NaN   \n",
      "938            NaN       2025-02-30       C1424          Tablet       8.0   \n",
      "955         T50615       2023-13-01         NaN          Tablet     -10.0   \n",
      "985            NaN       2023-13-01       C1969          Tablet     -10.0   \n",
      "999            NaN       2023-13-01       C1503  Coffee Machine     732.0   \n",
      "\n",
      "                  Price Payment_Method Transaction_Status  \n",
      "36   177.02705971474705         PayPal                NaN  \n",
      "41                  NaN        pay pal          Completed  \n",
      "73                  NaN         PayPal                NaN  \n",
      "78     974.004199673276        pay pal             Failed  \n",
      "90   -369.3383892220736     creditcard                NaN  \n",
      "..                  ...            ...                ...  \n",
      "936            $-838.21           Cash          completed  \n",
      "938             $322.39    credit card          Completed  \n",
      "955                 NaN           Cash          completed  \n",
      "985             $370.81         PayPal          Completed  \n",
      "999                 NaN           Cash           complete  \n",
      "\n",
      "[85 rows x 8 columns]\n",
      "\n",
      "Rows where numeric column 'Quantity' was filled with median:\n",
      "    Transaction_ID Transaction_Date Customer_ID    Product_Name  Quantity  \\\n",
      "17           T1762       2024-08-20       C2106      Headphones       NaN   \n",
      "57          T73692       2023-13-01       C2941      Smartphone       NaN   \n",
      "61          T61770       2023-13-01       C4718               T       NaN   \n",
      "74          T17934       2022-01-15       C2823          Tablet       NaN   \n",
      "75          T33609       2025-02-30       C2620     Coffee Mach       NaN   \n",
      "102         T82364       2022-05-16       C1199      Smartphone       NaN   \n",
      "126         T78469       2021-10-10       C1333          Tablet       NaN   \n",
      "129         T39332       2023-05-31        C957          Laptop       NaN   \n",
      "130         T48588       2023-12-13        C535  Coffee Machine       NaN   \n",
      "146          T5325       2023-13-01       C3180          Tablet       NaN   \n",
      "152         T41721       2023-06-13       C4174            Smar       NaN   \n",
      "176         T68425              NaN       C2158  Coffee Machine       NaN   \n",
      "201         T27919       2024-04-18       C3242      Headphones       NaN   \n",
      "240         T15153       2020-01-01       C2165      Smartphone       NaN   \n",
      "277         T56444       2022-12-12        C051             Tab       NaN   \n",
      "297         T72859       2023-13-01       C1074      Headphones       NaN   \n",
      "299         T58171       2023-13-01       C2322          Tablet       NaN   \n",
      "310         T16886       2024-09-18       C1740          Tablet       NaN   \n",
      "311         T49984              NaN       C1899      Smartphone       NaN   \n",
      "387          T0227       2023-13-01       C4300          Laptop       NaN   \n",
      "417         T30884       2023-01-09        C758  Coffee Machine       NaN   \n",
      "454         T94405       2024-09-09       C4469      Headphones       NaN   \n",
      "459         T16362       2023-13-01       C1780          Laptop       NaN   \n",
      "472         T93622       2025-02-30       C3590             Sma       NaN   \n",
      "512         T75962       2025-02-30       C2897             Tab       NaN   \n",
      "526         T15809       2023-13-01       C1770      Smartphone       NaN   \n",
      "540         T23788              NaN       C3918          Tablet       NaN   \n",
      "590         T80167       2023-13-01        C057             Tab       NaN   \n",
      "601          T9094       2021-11-16       C4734  Coffee Machine       NaN   \n",
      "626         T73647       2025-02-30       C1577  Coffee Machine       NaN   \n",
      "675         T47140       2020-12-16       C2406          Tablet       NaN   \n",
      "681         T34287              NaN       C1557  Coffee Machine       NaN   \n",
      "705         T91331       2023-13-01        C252  Coffee Machine       NaN   \n",
      "708         T75534       2023-13-01       C2161          Laptop       NaN   \n",
      "722         T55043       2025-02-30       C2672          Tablet       NaN   \n",
      "750         T34273       2023-13-01        C974         Smartph       NaN   \n",
      "766         T40039       2023-13-01       C3641          Laptop       NaN   \n",
      "774         T41047       2023-13-01        C866  Coffee Machine       NaN   \n",
      "816         T80648       2020-06-01       C1720  Coffee Machine       NaN   \n",
      "823         T69606       2025-02-30       C3578          Tablet       NaN   \n",
      "825         T84866       2023-13-01       C1046          Tablet       NaN   \n",
      "827         T74337              NaN       C2265      Smartphone       NaN   \n",
      "839         T98518       2023-13-01       C4074      Smartphone       NaN   \n",
      "870          T2175              NaN       C1255  Coffee Machine       NaN   \n",
      "880         T36138       2022-06-20        C936          Headph       NaN   \n",
      "892         T62661       2023-13-01       C4897          Tablet       NaN   \n",
      "899         T50179       2024-08-31       C2219              Ta       NaN   \n",
      "901          T0115       2023-13-01       C4022      Headphones       NaN   \n",
      "925         T42506       2025-02-30       C3976      Smartphone       NaN   \n",
      "930         T17774       2025-02-30        C505      Smartphone       NaN   \n",
      "956         T34824       2025-02-30        C290          Tablet       NaN   \n",
      "965         T28011       2023-13-01       C4474          Laptop       NaN   \n",
      "\n",
      "          Price Payment_Method Transaction_Status  \n",
      "17          NaN    Credit Card           complete  \n",
      "57   206.196237        PayPal           completed  \n",
      "61  -924.836564     creditcard             Failed  \n",
      "74  -595.410044    credit card           complete  \n",
      "75  -619.284014         PayPal          completed  \n",
      "102 -463.043193           Cash            Pending  \n",
      "126 -210.920000     creditcard                NaN  \n",
      "129         NaN    credit card          completed  \n",
      "130 -237.245608           Cash                NaN  \n",
      "146  936.072563    Credit Card          completed  \n",
      "152         NaN     creditcard             Failed  \n",
      "176 -189.725105         PayPal          Completed  \n",
      "201  155.118040           Cash            Pending  \n",
      "240         NaN    Credit Card             Failed  \n",
      "277  456.936048    credit card           complete  \n",
      "297  766.779230           Cash          Completed  \n",
      "299  312.170000           Cash             Failed  \n",
      "310 -373.313292         PayPal          completed  \n",
      "311 -269.601547    credit card          completed  \n",
      "387 -150.307808    Credit Card             Failed  \n",
      "417 -977.540000    credit card             Failed  \n",
      "454 -218.435636    Credit Card          Completed  \n",
      "459 -119.123402    credit card           complete  \n",
      "472         NaN    Credit Card          Completed  \n",
      "512 -511.277752         PayPal           complete  \n",
      "526         NaN     creditcard                NaN  \n",
      "540 -847.030232         PayPal                NaN  \n",
      "590 -720.910000        PayPal           completed  \n",
      "601   57.788109     creditcard                NaN  \n",
      "626 -486.997048        pay pal           complete  \n",
      "675  816.310917        pay pal          completed  \n",
      "681 -586.430000         PayPal           complete  \n",
      "705         NaN        pay pal           complete  \n",
      "708 -959.338416           Cash            Pending  \n",
      "722 -143.099405        PayPal                 NaN  \n",
      "750         NaN        PayPal                 NaN  \n",
      "766         NaN    Credit Card             Failed  \n",
      "774         NaN        PayPal                 NaN  \n",
      "816         NaN        pay pal          completed  \n",
      "823  178.290037    credit card          completed  \n",
      "825  277.060689     creditcard             Failed  \n",
      "827         NaN           Cash           complete  \n",
      "839 -418.142268           Cash          completed  \n",
      "870 -625.867182        PayPal                 NaN  \n",
      "880  394.507371    Credit Card          completed  \n",
      "892  525.327369    credit card           complete  \n",
      "899         NaN         PayPal           complete  \n",
      "901 -261.141993        pay pal            Pending  \n",
      "925 -104.712158         PayPal          completed  \n",
      "930 -316.801629         PayPal          Completed  \n",
      "956 -540.120000        PayPal           completed  \n",
      "965  827.552190        pay pal          completed  \n",
      "\n",
      "Rows where numeric column 'Price' was filled with median:\n",
      "    Transaction_ID Transaction_Date Customer_ID    Product_Name  Quantity  \\\n",
      "2           T19865       2023-13-01       C1106  Coffee Machine       5.0   \n",
      "3           T76700       2025-02-30       C3862  Coffee Machine       6.0   \n",
      "6           T84005       2025-02-30        C080      Headphones      -8.0   \n",
      "8           T60768       2020-08-30       C2386  Coffee Machine       2.0   \n",
      "9           T50075       2023-13-01       C3015          Tablet       6.0   \n",
      "..             ...              ...         ...             ...       ...   \n",
      "983         T72444       2025-02-30       C1604  Coffee Machine      -9.0   \n",
      "987         T90867       2020-08-03       C2788          Laptop     516.0   \n",
      "992         T68941       2024-12-24       C1759  Coffee Machine       9.0   \n",
      "994         T41077       2023-13-01        C744      Headphones      10.0   \n",
      "997         T78319       2023-10-08        C497      Smartphone     831.0   \n",
      "\n",
      "     Price Payment_Method Transaction_Status  \n",
      "2      NaN        pay pal                NaN  \n",
      "3      NaN           Cash             Failed  \n",
      "6      NaN           Cash                NaN  \n",
      "8      NaN     creditcard          Completed  \n",
      "9      NaN    Credit Card          Completed  \n",
      "..     ...            ...                ...  \n",
      "983    NaN        PayPal           completed  \n",
      "987    NaN     creditcard             Failed  \n",
      "992    NaN    credit card            Pending  \n",
      "994    NaN    credit card             Failed  \n",
      "997    NaN     creditcard             Failed  \n",
      "\n",
      "[310 rows x 8 columns]\n",
      "\n",
      "Rows where categorical/text column 'Transaction_Status' was filled with mode:\n",
      "    Transaction_ID Transaction_Date Customer_ID    Product_Name  Quantity  \\\n",
      "2           T19865       2023-13-01       C1106  Coffee Machine       5.0   \n",
      "6           T84005       2025-02-30        C080      Headphones      -8.0   \n",
      "13          T16639       2023-13-01       C4714      Smartphone       5.0   \n",
      "27          T94893       2025-02-30       C1328      Headphones     141.0   \n",
      "28          T92732       2025-02-30       C3429        Smartpho      -1.0   \n",
      "..             ...              ...         ...             ...       ...   \n",
      "959         T56730       2025-02-30       C4839          Tablet     921.0   \n",
      "972         T34339       2025-02-30       C3728          Laptop       2.0   \n",
      "974         T52507       2020-02-16       C3140          Laptop      -2.0   \n",
      "975         T84700       2025-02-30       C4051      Smartphone      -4.0   \n",
      "986         T85627       2025-02-30       C1601      Smartphone     550.0   \n",
      "\n",
      "          Price Payment_Method Transaction_Status  \n",
      "2    -75.238997        pay pal                NaN  \n",
      "6    -75.238997           Cash                NaN  \n",
      "13  -796.834515        PayPal                 NaN  \n",
      "27   -75.238997        PayPal                 NaN  \n",
      "28   691.990000    Credit Card                NaN  \n",
      "..          ...            ...                ...  \n",
      "959  682.889617     creditcard                NaN  \n",
      "972  -75.238997        pay pal                NaN  \n",
      "974 -236.657045        pay pal                NaN  \n",
      "975  -75.238997    credit card                NaN  \n",
      "986  612.258939     creditcard                NaN  \n",
      "\n",
      "[151 rows x 8 columns]\n",
      "\n",
      "Rows with negative or zero Quantity (will be set to NaN):\n",
      "    Transaction_ID Transaction_Date Customer_ID    Product_Name  Quantity  \\\n",
      "0           T75722       2022-07-21       C3456          Laptop      -9.0   \n",
      "4           T92992       2025-02-30        C321          Tablet      -7.0   \n",
      "6           T84005       2025-02-30        C080      Headphones      -8.0   \n",
      "10          T27702       2021-07-21       C3956          Laptop      -8.0   \n",
      "12          T45081       2023-13-01       C3691  Coffee Machine     -10.0   \n",
      "..             ...              ...         ...             ...       ...   \n",
      "975         T84700       2025-02-30       C4051      Smartphone      -4.0   \n",
      "980         T87038       2024-07-30       C4254      Smartphone      -6.0   \n",
      "981         T11148       2020-12-17       C1883      Smartphone      -5.0   \n",
      "983         T72444       2025-02-30       C1604  Coffee Machine      -9.0   \n",
      "996         T41131       2023-13-01       C2573      Smartphone      -4.0   \n",
      "\n",
      "          Price Payment_Method Transaction_Status  \n",
      "0    422.540623        PayPal           Completed  \n",
      "4    174.532239    Credit Card          completed  \n",
      "6    -75.238997           Cash          completed  \n",
      "10   649.308459    Credit Card            Pending  \n",
      "12   -75.238997    credit card           complete  \n",
      "..          ...            ...                ...  \n",
      "975  -75.238997    credit card          completed  \n",
      "980  944.050000           Cash          Completed  \n",
      "981  593.354908        PayPal           completed  \n",
      "983  -75.238997        PayPal           completed  \n",
      "996  577.585098        PayPal            complete  \n",
      "\n",
      "[290 rows x 8 columns]\n",
      "\n",
      "Rows with negative or zero Price (will be set to NaN):\n",
      "    Transaction_ID Transaction_Date Customer_ID    Product_Name  Quantity  \\\n",
      "1           T80185       2025-02-30        C080          Laptop       5.0   \n",
      "2           T19865       2023-13-01       C1106  Coffee Machine       5.0   \n",
      "3           T76700       2025-02-30       C3862  Coffee Machine       6.0   \n",
      "6           T84005       2025-02-30        C080      Headphones      -8.0   \n",
      "7           T80918       2023-13-01       C4989  Coffee Machine     681.0   \n",
      "..             ...              ...         ...             ...       ...   \n",
      "991         T31334       2023-13-01       C1095          Laptop       7.0   \n",
      "992         T68941       2024-12-24       C1759  Coffee Machine       9.0   \n",
      "994         T41077       2023-13-01        C744      Headphones      10.0   \n",
      "995         T16784       2020-03-14       C4881      Smartphone     855.0   \n",
      "997         T78319       2023-10-08        C497      Smartphone     831.0   \n",
      "\n",
      "          Price Payment_Method Transaction_Status  \n",
      "1   -773.452630    credit card          completed  \n",
      "2    -75.238997        pay pal          completed  \n",
      "3    -75.238997           Cash             Failed  \n",
      "6    -75.238997           Cash          completed  \n",
      "7   -164.936529           Cash          Completed  \n",
      "..          ...            ...                ...  \n",
      "991 -219.511100           Cash             Failed  \n",
      "992  -75.238997    credit card            Pending  \n",
      "994  -75.238997    credit card             Failed  \n",
      "995 -342.840873           Cash          completed  \n",
      "997  -75.238997     creditcard             Failed  \n",
      "\n",
      "[622 rows x 8 columns]\n",
      "\n",
      "Sample of text columns after standardization:\n",
      "0            laptop\n",
      "1            laptop\n",
      "2    coffee machine\n",
      "3    coffee machine\n",
      "4            tablet\n",
      "Name: Product_Name, dtype: object\n",
      "0         paypal\n",
      "1    credit card\n",
      "2        pay pal\n",
      "3           cash\n",
      "4    credit card\n",
      "Name: Payment_Method, dtype: object\n",
      "0    completed\n",
      "1    completed\n",
      "2    completed\n",
      "3       failed\n",
      "4    completed\n",
      "Name: Transaction_Status, dtype: object\n",
      "\n",
      "Sample Transaction_Date column after normalization:\n",
      "0   2022-07-21\n",
      "1          NaT\n",
      "2          NaT\n",
      "3          NaT\n",
      "4          NaT\n",
      "Name: Transaction_Date, dtype: datetime64[ns]\n",
      "\n",
      "Sample Payment_Method after standardization:\n",
      "0         PayPal\n",
      "1    Credit Card\n",
      "2         PayPal\n",
      "3           Cash\n",
      "4    Credit Card\n",
      "Name: Payment_Method, dtype: object\n",
      "\n",
      "Sample Transaction_Status after standardization:\n",
      "0    Completed\n",
      "1    Completed\n",
      "2    Completed\n",
      "3       Failed\n",
      "4    Completed\n",
      "Name: Transaction_Status, dtype: object\n",
      "\n",
      "Sample Product_Name after standardization:\n",
      "0            Laptop\n",
      "1            Laptop\n",
      "2    Coffee Machine\n",
      "3    Coffee Machine\n",
      "4            Tablet\n",
      "Name: Product_Name, dtype: object\n",
      "\n",
      "âœ… Data cleaning complete! Saved to 'diy_dataset.csv'\n",
      "Total rows after cleaning: 915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================================================\n",
    "# 1ï¸âƒ£ HANDLE MISSING VALUES\n",
    "# ===============================================================\n",
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values:\n",
    "    - Drop rows with missing Transaction_ID or Customer_ID.\n",
    "    - Clean and convert 'Price' and 'Quantity' to numeric before filling.\n",
    "    - Fill numeric columns with median.\n",
    "    - Fill categorical/text columns with mode.\n",
    "    Prints rows where changes occur for clarity.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ðŸ”¹ Identify rows with missing IDs (to drop)\n",
    "    missing_ids = df[df[\"Transaction_ID\"].isna() | df[\"Customer_ID\"].isna()]\n",
    "    if not missing_ids.empty:\n",
    "        print(\"Rows with missing Transaction_ID or Customer_ID (will be dropped):\")\n",
    "        print(missing_ids)\n",
    "    \n",
    "    # Drop invalid ID rows\n",
    "    df = df.dropna(subset=[\"Transaction_ID\", \"Customer_ID\"])\n",
    "\n",
    "    # ðŸ”¹ Special cleanup for numeric-like object columns (e.g., 'Price', 'Quantity')\n",
    "    numeric_like_cols = [\"Price\", \"Quantity\"]\n",
    "    for col in numeric_like_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str)\n",
    "                .str.replace(r\"[^0-9.\\-]\", \"\", regex=True)\n",
    "            )\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # ðŸ”¹ Fill missing values\n",
    "    for col in df.columns:\n",
    "        if col in [\"Transaction_ID\", \"Customer_ID\", \"Transaction_Date\"]:\n",
    "            continue  # IDs handled separately and skip Date\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            null_rows = df[df[col].isna()]\n",
    "            if not null_rows.empty:\n",
    "                print(f\"\\nRows where numeric column '{col}' was filled with median:\")\n",
    "                print(null_rows)\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "        else:\n",
    "            null_rows = df[df[col].isna()]\n",
    "            if not null_rows.empty:\n",
    "                print(f\"\\nRows where categorical/text column '{col}' was filled with mode:\")\n",
    "                print(null_rows)\n",
    "            df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"Unknown\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 2ï¸âƒ£ HANDLE INVALID VALUES (TYPE & RANGE)\n",
    "# ===============================================================\n",
    "def handle_invalid_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove symbols from Price\n",
    "    if \"Price\" in df.columns:\n",
    "        df[\"Price\"] = df[\"Price\"].astype(str).str.replace(r\"[^0-9.\\-]\", \"\", regex=True)\n",
    "\n",
    "    df[\"Quantity\"] = pd.to_numeric(df[\"Quantity\"], errors=\"coerce\")\n",
    "    df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors=\"coerce\")\n",
    "\n",
    "    # Show rows before changes\n",
    "    neg_quantity_rows = df[df[\"Quantity\"] <= 0]\n",
    "    neg_price_rows = df[df[\"Price\"] <= 0]\n",
    "    non_int_quantity_rows = df[~df[\"Quantity\"].dropna().apply(float.is_integer)]\n",
    "\n",
    "    if not neg_quantity_rows.empty:\n",
    "        print(\"\\nRows with negative or zero Quantity (will be set to NaN):\")\n",
    "        print(neg_quantity_rows)\n",
    "    if not neg_price_rows.empty:\n",
    "        print(\"\\nRows with negative or zero Price (will be set to NaN):\")\n",
    "        print(neg_price_rows)\n",
    "    if not non_int_quantity_rows.empty:\n",
    "        print(\"\\nRows with non-integer Quantity (will be set to NaN):\")\n",
    "        print(non_int_quantity_rows)\n",
    "\n",
    "    # Replace negative or zero values with NaN\n",
    "    df.loc[df[\"Quantity\"] <= 0, \"Quantity\"] = np.nan\n",
    "    df.loc[df[\"Price\"] <= 0, \"Price\"] = np.nan\n",
    "\n",
    "    # Remove non-integer quantities\n",
    "    df.loc[~df[\"Quantity\"].isna(), \"Quantity\"] = df[\"Quantity\"].apply(\n",
    "        lambda x: x if float(x).is_integer() else np.nan\n",
    "    )\n",
    "\n",
    "    # Round price to 2 decimals\n",
    "    df[\"Price\"] = df[\"Price\"].round(2)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3ï¸âƒ£ STANDARDIZE TEXT CASES\n",
    "# ===============================================================\n",
    "def standardize_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include=\"object\"):\n",
    "        df.loc[:, col] = df[col].astype(str).str.strip().str.lower()\n",
    "    # Show sample of text columns after standardization\n",
    "    print(\"\\nSample of text columns after standardization:\")\n",
    "    for col in [\"Product_Name\", \"Payment_Method\", \"Transaction_Status\"]:\n",
    "        if col in df.columns:\n",
    "            print(df[col].head(5))\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 4ï¸âƒ£ NORMALIZE DATE FORMATS\n",
    "# ===============================================================\n",
    "def normalize_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"Transaction_Date\"] = pd.to_datetime(df[\"Transaction_Date\"], errors=\"coerce\")\n",
    "    # Format only non-null dates\n",
    "    df.loc[~df[\"Transaction_Date\"].isna(), \"Transaction_Date\"] = df.loc[~df[\"Transaction_Date\"].isna(), \"Transaction_Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    # Show sample after normalization\n",
    "    print(\"\\nSample Transaction_Date column after normalization:\")\n",
    "    print(df[\"Transaction_Date\"].head(5))\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 5ï¸âƒ£ STANDARDIZE CATEGORICAL VALUES\n",
    "# ===============================================================\n",
    "def standardize_categories(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    payment_map = {\n",
    "        \"paypal\": \"PayPal\", \"pay pal\": \"PayPal\",\n",
    "        \"creditcard\": \"Credit Card\", \"credit card\": \"Credit Card\",\n",
    "        \"cash\": \"Cash\",\n",
    "    }\n",
    "\n",
    "    status_map = {\n",
    "        \"completed\": \"Completed\", \"complete\": \"Completed\",\n",
    "        \"pending\": \"Pending\", \"failed\": \"Failed\",\n",
    "    }\n",
    "\n",
    "    product_map = {\n",
    "        # Laptop variants\n",
    "        \"laptop\": \"Laptop\", \"lap\": \"Laptop\", \"lapto\": \"Laptop\", \"lapt\": \"Laptop\",\n",
    "        \"la\": \"Laptop\", \"l\": \"Laptop\",\n",
    "\n",
    "        # Coffee Machine variants\n",
    "        \"coffee machine\": \"Coffee Machine\", \"coffee machin\": \"Coffee Machine\",\n",
    "        \"coffee mach\": \"Coffee Machine\", \"coffee mac\": \"Coffee Machine\",\n",
    "        \"coffee machi\": \"Coffee Machine\", \"coffee ma\": \"Coffee Machine\",\n",
    "        \"coffee m\": \"Coffee Machine\", \"coffee\": \"Coffee Machine\",\n",
    "        \"coffe\": \"Coffee Machine\", \"coff\": \"Coffee Machine\", \"cof\": \"Coffee Machine\",\n",
    "        \"c\": \"Coffee Machine\",\n",
    "\n",
    "        # Tablet variants\n",
    "        \"tablet\": \"Tablet\", \"table\": \"Tablet\", \"tabl\": \"Tablet\",\n",
    "        \"tab\": \"Tablet\", \"ta\": \"Tablet\",\n",
    "\n",
    "        # Smartphone variants\n",
    "        \"smartphone\": \"Smartphone\", \"smartphon\": \"Smartphone\",\n",
    "        \"smartph\": \"Smartphone\", \"smartp\": \"Smartphone\",\n",
    "        \"smartpho\": \"Smartphone\", \"smart\": \"Smartphone\",\n",
    "        \"smar\": \"Smartphone\", \"sma\": \"Smartphone\",\n",
    "        \"sm\": \"Smartphone\", \"t\": \"Smartphone\", \"s\": \"Smartphone\",\n",
    "\n",
    "        # Headphones variants\n",
    "        \"headphones\": \"Headphones\", \"headphone\": \"Headphones\",\n",
    "        \"headpho\": \"Headphones\", \"headph\": \"Headphones\",\n",
    "        \"head\": \"Headphones\", \"he\": \"Headphones\", \"h\": \"Headphones\"\n",
    "    }\n",
    "\n",
    "    valid_products = [\"Laptop\", \"Coffee Machine\", \"Tablet\", \"Smartphone\", \"Headphones\"]\n",
    "\n",
    "    def fuzzy_match(value: str, mapping: dict, valid_list: list[str], threshold: int = 70) -> str:\n",
    "        \"\"\"Return mapped value, fuzzy match, or original if no close match.\"\"\"\n",
    "        if not isinstance(value, str):\n",
    "            return value\n",
    "        v = value.strip().lower()\n",
    "        if v in mapping:\n",
    "            return mapping[v]\n",
    "        match, score, _ = process.extractOne(v, valid_list, scorer=fuzz.token_sort_ratio)\n",
    "        return match if score >= threshold else value\n",
    "\n",
    "    # --- Standardize columns ---\n",
    "    if \"Payment_Method\" in df.columns:\n",
    "        df[\"Payment_Method\"] = df[\"Payment_Method\"].map(\n",
    "            lambda x: payment_map.get(str(x).lower(), x) if pd.notna(x) else x\n",
    "        )\n",
    "        print(\"\\nSample Payment_Method after standardization:\")\n",
    "        print(df[\"Payment_Method\"].head(5))\n",
    "\n",
    "    if \"Transaction_Status\" in df.columns:\n",
    "        df[\"Transaction_Status\"] = df[\"Transaction_Status\"].map(\n",
    "            lambda x: status_map.get(str(x).lower(), x) if pd.notna(x) else x\n",
    "        )\n",
    "        print(\"\\nSample Transaction_Status after standardization:\")\n",
    "        print(df[\"Transaction_Status\"].head(5))\n",
    "\n",
    "    if \"Product_Name\" in df.columns:\n",
    "        df[\"Product_Name\"] = df[\"Product_Name\"].map(\n",
    "            lambda x: fuzzy_match(str(x), product_map, valid_products) if pd.notna(x) else x\n",
    "        )\n",
    "        print(\"\\nSample Product_Name after standardization:\")\n",
    "        print(df[\"Product_Name\"].head(5))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# ðŸ§¹ MAIN CLEANING PIPELINE\n",
    "# ===============================================================\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = handle_missing_values(df)\n",
    "    df = handle_invalid_values(df)\n",
    "    df = standardize_text(df)\n",
    "    df = normalize_dates(df)\n",
    "    df = standardize_categories(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# âœ… EXECUTE PIPELINE\n",
    "# ===============================================================\n",
    "df = pd.read_csv(\"dirty_financial_transactions_1k.csv\")\n",
    "cleaned_df = clean_data(df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_df.to_csv(\"diy_dataset.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Data cleaning complete! Saved to 'diy_dataset.csv'\")\n",
    "print(f\"Total rows after cleaning: {len(cleaned_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cleaned_df.head())\n",
    "# print(df.info())\n",
    "# print(cleaned_df.info())\n",
    "# for i in cleaned_df.columns:\n",
    "#     if isinstance(i, object):\n",
    "#         print(cleaned_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Coffee Machine â€” Top 3 Payment Methods by Total Sales:\n",
      "Payment_Method  Total_Sales\n",
      "   Credit Card   4504366.93\n",
      "        PayPal   3292386.00\n",
      "          Cash     72982.21\n",
      "\n",
      "ðŸ“¦ Headphones â€” Top 3 Payment Methods by Total Sales:\n",
      "Payment_Method  Total_Sales\n",
      "   Credit Card   2410223.70\n",
      "        PayPal   1302175.23\n",
      "          Cash    358524.11\n",
      "\n",
      "ðŸ“¦ Laptop â€” Top 3 Payment Methods by Total Sales:\n",
      "Payment_Method  Total_Sales\n",
      "   Credit Card   2625884.03\n",
      "        PayPal   1866780.85\n",
      "          Cash     11173.37\n",
      "\n",
      "ðŸ“¦ Smartphone â€” Top 3 Payment Methods by Total Sales:\n",
      "Payment_Method  Total_Sales\n",
      "   Credit Card   3974654.06\n",
      "        PayPal   2206921.59\n",
      "          Cash    738708.15\n",
      "\n",
      "ðŸ“¦ Tablet â€” Top 3 Payment Methods by Total Sales:\n",
      "Payment_Method  Total_Sales\n",
      "        PayPal   3900292.98\n",
      "   Credit Card   3332883.09\n",
      "          Cash    527724.92\n",
      "\n",
      "ðŸ’µ Average Price (Cash payments only):\n",
      "  Product_Name  Price\n",
      "    Smartphone 615.74\n",
      "        Laptop 578.85\n",
      "        Tablet 483.77\n",
      "Coffee Machine 480.97\n",
      "    Headphones 433.14\n",
      "\n",
      "ðŸ“Š Percentage of Total Sales by Product:\n",
      "  Product_Name  Total_Sales  Sales_%\n",
      "Coffee Machine   7869735.14    25.28\n",
      "        Tablet   7760900.99    24.93\n",
      "    Smartphone   6920283.80    22.23\n",
      "        Laptop   4503838.25    14.47\n",
      "    Headphones   4070923.04    13.08\n",
      "\n",
      "ðŸ“† Average Sales by Month (All Years Combined):\n",
      "Month_Name  Total_Sales\n",
      "   January     33118.81\n",
      "  February     49730.04\n",
      "     March     75532.35\n",
      "     April     36217.33\n",
      "       May     38908.43\n",
      "      June      9670.75\n",
      "      July     45702.12\n",
      "    August      6054.43\n",
      " September     55273.46\n",
      "   October     12476.71\n",
      "  November     24693.48\n",
      "  December      3358.06\n",
      "\n",
      "ðŸ“Š Standard Deviation of Price by Payment Method:\n",
      "Payment_Method  Price\n",
      "          Cash 275.54\n",
      "   Credit Card 272.35\n",
      "        PayPal 246.32\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# a. Top-N within each group\n",
    "# ===============================================================\n",
    "df = cleaned_df.copy()\n",
    "\n",
    "# Handle missing values\n",
    "df[\"Quantity\"] = df[\"Quantity\"].fillna(0)\n",
    "df[\"Price\"] = df[\"Price\"].fillna(0)\n",
    "\n",
    "# Compute total sales\n",
    "df[\"Total_Sales\"] = df[\"Price\"] * df[\"Quantity\"]\n",
    "\n",
    "# Group and aggregate\n",
    "sales_summary = (\n",
    "    df.groupby([\"Product_Name\", \"Payment_Method\"], dropna=False)[\"Total_Sales\"]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Sort within each product\n",
    "sales_summary = sales_summary.sort_values(\n",
    "    [\"Product_Name\", \"Total_Sales\"], ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Get top 3 payment methods for each product\n",
    "top3_by_product = (\n",
    "    sales_summary.groupby(\"Product_Name\")\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Display results cleanly\n",
    "for product, subdf in top3_by_product.groupby(\"Product_Name\"):\n",
    "    print(f\"\\nðŸ“¦ {product} â€” Top 3 Payment Methods by Total Sales:\")\n",
    "    print(subdf[[\"Payment_Method\", \"Total_Sales\"]].to_string(index=False))\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# c. Conditional aggregation\n",
    "# ===============================================================\n",
    "df_cash = cleaned_df.copy()\n",
    "\n",
    "# Filter for Cash payments only\n",
    "df_cash = df_cash[df_cash[\"Payment_Method\"].str.lower() == \"cash\"]\n",
    "\n",
    "# Handle missing prices safely\n",
    "df_cash = df_cash[df_cash[\"Price\"].notna()]\n",
    "\n",
    "# Compute average price per product\n",
    "avg_price_by_product = (\n",
    "    df_cash.groupby(\"Product_Name\")[\"Price\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    "    .sort_values(\"Price\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’µ Average Price (Cash payments only):\")\n",
    "print(avg_price_by_product.to_string(index=False))\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# d. Percentage Distribution\n",
    "# ===============================================================\n",
    "df_sales = cleaned_df.copy()\n",
    "\n",
    "# Handle missing values\n",
    "df_sales[\"Price\"] = df_sales[\"Price\"].fillna(0)\n",
    "df_sales[\"Quantity\"] = df_sales[\"Quantity\"].fillna(0)\n",
    "\n",
    "# Compute total sales per row\n",
    "df_sales[\"Total_Sales\"] = df_sales[\"Price\"] * df_sales[\"Quantity\"]\n",
    "\n",
    "# Sum sales by product\n",
    "product_sales = (\n",
    "    df_sales.groupby(\"Product_Name\")[\"Total_Sales\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute percentage contribution\n",
    "total_sales_sum = product_sales[\"Total_Sales\"].sum()\n",
    "product_sales[\"Sales_%\"] = (product_sales[\"Total_Sales\"] / total_sales_sum * 100).round(2)\n",
    "\n",
    "# Sort by percentage (descending)\n",
    "product_sales = product_sales.sort_values(\"Sales_%\", ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Percentage of Total Sales by Product:\")\n",
    "print(product_sales.to_string(index=False))\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# e. Change over time\n",
    "# ===============================================================\n",
    "df_monthly = cleaned_df.copy()\n",
    "\n",
    "# Ensure proper datatypes\n",
    "df_monthly[\"Transaction_Date\"] = pd.to_datetime(df_monthly[\"Transaction_Date\"], errors=\"coerce\")\n",
    "\n",
    "# Handle missing values\n",
    "df_monthly[\"Price\"] = df_monthly[\"Price\"].fillna(0)\n",
    "df_monthly[\"Quantity\"] = df_monthly[\"Quantity\"].fillna(0)\n",
    "\n",
    "# Compute total sales per transaction\n",
    "df_monthly[\"Total_Sales\"] = df_monthly[\"Price\"] * df_monthly[\"Quantity\"]\n",
    "\n",
    "# Extract month number and name\n",
    "df_monthly[\"Month_Num\"] = df_monthly[\"Transaction_Date\"].dt.month\n",
    "df_monthly[\"Month_Name\"] = df_monthly[\"Transaction_Date\"].dt.strftime(\"%B\")\n",
    "\n",
    "# Group by month (across all years)\n",
    "avg_sales_by_month = (\n",
    "    df_monthly.groupby([\"Month_Num\", \"Month_Name\"])[\"Total_Sales\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    "    .reset_index()\n",
    "    .sort_values(\"Month_Num\")\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“† Average Sales by Month (All Years Combined):\")\n",
    "print(avg_sales_by_month[[\"Month_Name\", \"Total_Sales\"]].to_string(index=False))\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# e. Change over time\n",
    "# ===============================================================\n",
    "df_sd = cleaned_df.copy()\n",
    "\n",
    "# Drop rows with missing or invalid price/payment values\n",
    "df_sd = df_sd[df_sd[\"Price\"].notna() & df_sd[\"Payment_Method\"].notna()]\n",
    "\n",
    "# Group by payment method and compute standard deviation of price\n",
    "std_price_by_payment = (\n",
    "    df_sd.groupby(\"Payment_Method\")[\"Price\"]\n",
    "    .std()              # standard deviation\n",
    "    .round(2)           # round to 2 decimals\n",
    "    .reset_index()\n",
    "    .sort_values(\"Price\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Standard Deviation of Price by Payment Method:\")\n",
    "print(std_price_by_payment.to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
